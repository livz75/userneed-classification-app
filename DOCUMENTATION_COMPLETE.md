# ğŸ“š Documentation ComplÃ¨te - Application d'Analyse IA des Userneeds Franceinfo

## ğŸ“‹ Table des matiÃ¨res

1. [Vue d'ensemble](#vue-densemble)
2. [Architecture technique](#architecture-technique)
3. [Installation et dÃ©ploiement](#installation-et-dÃ©ploiement)
4. [Guide d'utilisation](#guide-dutilisation)
5. [Configuration](#configuration)
6. [API et intÃ©grations](#api-et-intÃ©grations)
7. [DÃ©veloppement](#dÃ©veloppement)
8. [Maintenance et troubleshooting](#maintenance-et-troubleshooting)
9. [Roadmap et Ã©volutions](#roadmap-et-Ã©volutions)

---

## Vue d'ensemble

### ğŸ¯ Objectif

L'application **Analyse IA des Userneeds** est un outil d'analyse automatique et de classification des articles Franceinfo selon leurs "user needs" (besoins utilisateur) en utilisant des modÃ¨les d'intelligence artificielle de pointe.

### ğŸ¨ Contexte mÃ©tier

France TÃ©lÃ©visions utilise une taxonomie de 8 "userneeds" pour classifier le contenu Ã©ditorial :

1. **UPDATE ME** - ActualitÃ©s et mises Ã  jour
2. **EXPLAIN ME** - Explications et pÃ©dagogie
3. **GIVE ME PERSPECTIVE** - Analyses et contexte
4. **GIVE ME A BREAK** - Divertissement et pause
5. **GIVE ME CONCERNING NEWS** - ActualitÃ©s prÃ©occupantes
6. **INSPIRE ME** - Inspiration et dÃ©couverte
7. **MAKE ME FEEL THE NEWS** - Ã‰motion et vÃ©cu
8. **REVEAL NEWS** - RÃ©vÃ©lations et enquÃªtes

### âœ¨ FonctionnalitÃ©s principales

- âœ… **Analyse batch** : Upload d'un fichier Excel avec plusieurs articles
- âœ… **Multi-LLM** : Support de 13+ modÃ¨les d'IA (Claude, GPT, Gemini, Llama, Mistral, etc.)
- âœ… **Classification Ã  3 niveaux** : Userneed principal, secondaire et tertiaire avec scores
- âœ… **Matrice de confusion** : Visualisation interactive des rÃ©sultats
- âœ… **Export Excel** : TÃ©lÃ©chargement des rÃ©sultats avec statistiques
- âœ… **Prompts personnalisables** : Modification des instructions IA
- âœ… **ThÃ¨mes** : Mode clair et sombre

### ğŸ“Š MÃ©triques clÃ©s

- **Temps d'analyse** : 3-5 secondes par article (selon le modÃ¨le)
- **PrÃ©cision** : 70-85% de concordance selon le modÃ¨le LLM utilisÃ©
- **CapacitÃ©** : Analyse de 100+ articles en une session
- **DisponibilitÃ©** : 24/7 via dÃ©ploiement cloud (Render.com)

---

## Architecture technique

### ğŸ—ï¸ Stack technologique

**Frontend**
- HTML5, CSS3, JavaScript (Vanilla)
- Design responsive avec systÃ¨me de grille CSS
- Police : Poppins (Google Fonts)
- Pas de framework (vanilla JS pour simplicitÃ© et performance)

**Backend**
- Python 3.12
- `http.server` (serveur HTTP simple)
- `socketserver` (gestion des connexions)
- `urllib` (requÃªtes API)

**APIs externes**
- **OpenRouter** : Gateway unifiÃ© pour accÃ©der Ã  13+ modÃ¨les LLM
- Support API Anthropic direct (legacy)

**DÃ©ploiement**
- **Production** : Render.com
- **Repository** : GitHub (https://github.com/livz75/userneed-classification-app)
- **CI/CD** : Auto-deploy depuis branch `main`

### ğŸ“ Structure du projet

```
userneed-classification-app/
â”œâ”€â”€ index.html              # Interface utilisateur principale
â”œâ”€â”€ style.css               # Styles (thÃ¨mes clair/sombre)
â”œâ”€â”€ script.js               # Logique frontend (2,356 lignes)
â”œâ”€â”€ server.py               # Serveur proxy Python
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”œâ”€â”€ render.yaml            # Configuration Render.com
â”œâ”€â”€ .python-version        # Version Python (3.12)
â”œâ”€â”€ .gitignore             # Fichiers ignorÃ©s par Git
â”‚
â”œâ”€â”€ api/                   # Fonctions serverless (Vercel legacy)
â”‚   â”œâ”€â”€ index.py
â”‚   â”œâ”€â”€ analyze.py
â”‚   â””â”€â”€ health.py
â”‚
â”œâ”€â”€ assets/                # Ressources statiques
â”‚   â””â”€â”€ franceinfo.jpg     # Logo Franceinfo
â”‚
â”œâ”€â”€ CONFIG.md              # Guide de configuration
â”œâ”€â”€ README.md              # Documentation utilisateur
â”œâ”€â”€ DOCUMENTATION_COMPLETE.md  # Ce fichier
â””â”€â”€ config.json.example    # Template de configuration
```

### ğŸ”„ Flux de donnÃ©es

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Utilisateur â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ 1. Upload Excel
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚ (index.html + script.js)
â”‚   - Parsing XLSXâ”‚
â”‚   - Validation  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ 2. POST /api/analyze (par article)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Backend       â”‚ (server.py)
â”‚   - CORS        â”‚
â”‚   - Proxy       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ 3. API Call
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   OpenRouter    â”‚
â”‚   - Claude      â”‚
â”‚   - GPT         â”‚
â”‚   - Gemini      â”‚
â”‚   - Llama       â”‚
â”‚   - Mistral     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ 4. RÃ©ponse JSON
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚
â”‚   - Parsing     â”‚
â”‚   - Matrice     â”‚
â”‚   - Export      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ” SÃ©curitÃ©

**Protection des clÃ©s API**
- âœ… Fichier `config.json` dans `.gitignore` (jamais committÃ©)
- âœ… ClÃ©s stockÃ©es en localStorage (fallback)
- âœ… Transmission sÃ©curisÃ©e via HTTPS
- âœ… Headers CORS configurÃ©s

**Validation des donnÃ©es**
- âœ… Validation format Excel cÃ´tÃ© frontend
- âœ… Sanitization des inputs utilisateur
- âœ… Timeout sur les requÃªtes API (120 secondes)
- âœ… Gestion des erreurs robuste

---

## Installation et dÃ©ploiement

### ğŸ’» Installation locale

#### PrÃ©requis

- Python 3.12+
- Navigateur web moderne (Chrome, Firefox, Safari, Edge)
- ClÃ© API OpenRouter (obtenir sur https://openrouter.ai)

#### Ã‰tapes d'installation

1. **Cloner le repository**
```bash
git clone https://github.com/livz75/userneed-classification-app.git
cd userneed-classification-app
```

2. **Installer les dÃ©pendances Python**
```bash
pip install -r requirements.txt
```

3. **Configurer les clÃ©s API**

CrÃ©er le fichier `config.json` Ã  la racine :
```json
{
  "anthropic_api_key": "sk-ant-...",
  "openrouter_api_key": "sk-or-v1-...",
  "default_provider": "openrouter",
  "default_model": "anthropic/claude-3.5-haiku"
}
```

4. **DÃ©marrer le serveur**
```bash
python3 server.py
```

5. **Ouvrir l'application**
```
http://localhost:8000
```

#### Script de dÃ©marrage automatique

Un script `start.sh` est fourni :
```bash
chmod +x start.sh
./start.sh
```

### ğŸš€ DÃ©ploiement sur Render.com

#### Configuration automatique

Le fichier `render.yaml` configure automatiquement :

```yaml
services:
  - type: web
    name: userneed-classification-app
    env: python
    buildCommand: "pip install -r requirements.txt"
    startCommand: "python server.py"
    envVars:
      - key: PORT
        value: 8000
```

#### Ã‰tapes de dÃ©ploiement

1. **CrÃ©er un compte Render**
   - Aller sur https://render.com
   - Se connecter avec GitHub

2. **CrÃ©er un Web Service**
   - Cliquer "New +" â†’ "Web Service"
   - SÃ©lectionner le repository `userneed-classification-app`
   - Render dÃ©tecte automatiquement `render.yaml`

3. **Configurer**
   - **Plan** : Free (gratuit)
   - **Branch** : main
   - Les autres champs sont prÃ©-remplis par `render.yaml`

4. **DÃ©ployer**
   - Cliquer "Create Web Service"
   - Attendre 2-3 minutes

5. **URL de production**
   ```
   https://userneed-classification-app.onrender.com
   ```

#### Variables d'environnement (optionnel)

Dans Render Dashboard â†’ Settings â†’ Environment Variables :
- `PORT` : Automatiquement dÃ©fini par Render
- `OPENROUTER_API_KEY` : (Optionnel) ClÃ© API prÃ©-configurÃ©e

### ğŸ”„ Mises Ã  jour automatiques

Chaque push sur la branche `main` dÃ©clenche un redÃ©ploiement automatique sur Render.

```bash
git add .
git commit -m "Update: description des changements"
git push origin main
```

---

## Guide d'utilisation

### ğŸ¬ DÃ©marrage rapide

#### 1. PrÃ©parer le fichier Excel

Format requis :
```
| url                           | titre                    | userneeds   |
|-------------------------------|--------------------------|-------------|
| https://franceinfo.fr/...     | Titre de l'article       | UPDATE ME   |
| https://franceinfo.fr/...     | Autre article            | EXPLAIN ME  |
```

**Colonnes obligatoires** :
- `url` : URL de l'article
- `titre` : Titre de l'article
- `userneeds` ou `userneed` : Userneed attendu

**Colonnes optionnelles** :
- `chapo` : ChapÃ´/sous-titre
- `corps` : Corps de l'article

#### 2. Charger le fichier

1. Cliquer sur **"ğŸ“ Fichier"**
2. SÃ©lectionner votre fichier `.xlsx`
3. Attendre le chargement (preview s'affiche)

#### 3. Configurer l'analyse (optionnel)

**Choisir le provider et modÃ¨le** :
1. Cliquer sur **"ğŸ¦™ LLM"**
2. SÃ©lectionner le provider : **OpenRouter** (recommandÃ©)
3. Choisir le modÃ¨le :
   - **Rapide** : `google/gemini-2.5-flash-lite`
   - **QualitÃ©** : `anthropic/claude-3.5-haiku`
   - **Gratuit** : `meta-llama/llama-3.1-8b-instruct`

**Modifier les prompts** (avancÃ©) :
1. Cliquer sur **"ğŸ“ PROMPTS"**
2. Ã‰diter le prompt systÃ¨me ou utilisateur
3. Sauvegarder

#### 4. Lancer l'analyse

1. Cliquer sur **"Analyse IA"**
2. Suivre la progression en temps rÃ©el
3. PossibilitÃ© d'arrÃªter avec **"ğŸ›‘ Stop"**

#### 5. Consulter les rÃ©sultats

**Tableau dÃ©taillÃ©**
- Colonnes : Titre, Userneed attendu, PrÃ©dictions (3 niveaux), Scores, Concordance
- Filtrage par clic sur matrice

**Matrice de confusion**
- Visualisation 8Ã—8
- Lignes : Userneeds attendus
- Colonnes : Userneeds prÃ©dits
- Cellules : Nombre d'articles
- **Interaction** : Clic sur cellule â†’ filtre le tableau

**Statistiques**
- Total articles analysÃ©s
- Taux de concordance global
- Distribution par userneed
- Top reclassifications

#### 6. Exporter les rÃ©sultats

1. Cliquer sur **"ğŸ“¥ Exporter Excel"**
2. Le fichier tÃ©lÃ©chargÃ© contient 3 feuilles :
   - **RÃ©sultats** : Tableau complet
   - **Matrice** : Matrice de confusion
   - **Statistiques** : MÃ©triques globales

### ğŸ¨ Personnalisation

#### Changer le thÃ¨me

Cliquer sur **ğŸŒ™/â˜€ï¸** en haut Ã  droite pour basculer entre :
- **Mode sombre** (par dÃ©faut)
- **Mode clair**

Le choix est sauvegardÃ© dans le navigateur.

#### GÃ©rer les prompts

**CrÃ©er un nouveau prompt** :
1. Ouvrir **"PROMPTS"**
2. Modifier le texte
3. Cliquer **"ğŸ’¾ Sauvegarder"**

**Exporter les prompts** :
```json
{
  "system": "Analyse cet article...",
  "user": "Article: {TITLE}\n\n{CONTENT}"
}
```

**RÃ©initialiser** :
Cliquer sur **"ğŸ”„ RÃ©initialiser"** pour revenir aux prompts par dÃ©faut.

---

## Configuration

### ğŸ”‘ Gestion des clÃ©s API

#### Option 1 : Fichier config.json (recommandÃ©)

CrÃ©er `config.json` Ã  la racine :
```json
{
  "anthropic_api_key": "sk-ant-api03-...",
  "openrouter_api_key": "sk-or-v1-...",
  "default_provider": "openrouter",
  "default_model": "anthropic/claude-3.5-haiku"
}
```

**Avantages** :
- âœ… Plus sÃ»r que localStorage
- âœ… Prioritaire sur les autres mÃ©thodes
- âœ… ProtÃ©gÃ© par `.gitignore`

#### Option 2 : Interface utilisateur

1. Ouvrir **"PROMPTS"**
2. Section "Configuration API"
3. Coller la clÃ© OpenRouter
4. SauvegardÃ© dans localStorage du navigateur

#### Option 3 : Variables d'environnement (production)

Sur Render.com â†’ Settings â†’ Environment Variables :
```
OPENROUTER_API_KEY=sk-or-v1-...
```

### ğŸ›ï¸ Ordre de prioritÃ©

L'application charge les clÃ©s dans cet ordre :
1. **Fichier config.json** (prioritaire)
2. **localStorage du navigateur**
3. **Saisie manuelle** via interface

### ğŸ¦™ ModÃ¨les LLM disponibles

#### Via OpenRouter

| ModÃ¨le | Provider | CoÃ»t | Vitesse | QualitÃ© | Cas d'usage |
|--------|----------|------|---------|---------|-------------|
| `anthropic/claude-3.5-haiku` | Anthropic | $ | âš¡âš¡âš¡ | â­â­â­â­ | RecommandÃ© - Ã‰quilibre qualitÃ©/vitesse |
| `openai/gpt-4o-mini` | OpenAI | $ | âš¡âš¡âš¡ | â­â­â­â­ | Rapide et performant |
| `google/gemini-2.5-flash-lite` | Google | $ | âš¡âš¡âš¡âš¡ | â­â­â­ | Ultra-rapide, Ã©conomique |
| `google/gemini-flash-1.5` | Google | $ | âš¡âš¡âš¡âš¡ | â­â­â­ | TrÃ¨s rapide |
| `meta-llama/llama-3.1-8b-instruct` | Meta | **GRATUIT** | âš¡âš¡âš¡âš¡ | â­â­â­ | Tests et dÃ©veloppement |
| `meta-llama/llama-3.3-70b-instruct` | Meta | $ | âš¡âš¡ | â­â­â­â­ | Haute qualitÃ© |
| `mistralai/mistral-small-24b-instruct-2501` | Mistral | $ | âš¡âš¡âš¡ | â­â­â­ | Bon rapport qualitÃ©/prix |
| `qwen/qwen-2.5-72b-instruct` | Alibaba | $ | âš¡âš¡ | â­â­â­â­ | Alternative qualitÃ© |
| `anthropic/claude-3.5-sonnet` | Anthropic | $$$ | âš¡ | â­â­â­â­â­ | Meilleure qualitÃ© (lent) |
| `openai/gpt-4-turbo` | OpenAI | $$$ | âš¡âš¡ | â­â­â­â­â­ | TrÃ¨s haute qualitÃ© |

**LÃ©gende** :
- **CoÃ»t** : $ (Ã©conomique), $$ (moyen), $$$ (Ã©levÃ©)
- **Vitesse** : âš¡ (lent) Ã  âš¡âš¡âš¡âš¡ (ultra-rapide)
- **QualitÃ©** : â­â­â­ (correcte) Ã  â­â­â­â­â­ (excellente)

#### Recommandations par cas d'usage

- **Production** : `anthropic/claude-3.5-haiku`
- **Tests/DÃ©mo** : `meta-llama/llama-3.1-8b-instruct` (gratuit)
- **RapiditÃ©** : `google/gemini-2.5-flash-lite`
- **QualitÃ© maximale** : `anthropic/claude-3.5-sonnet`
- **Budget limitÃ©** : `mistralai/mistral-small-24b-instruct-2501`

---

## API et intÃ©grations

### ğŸ”Œ Endpoints du serveur

#### GET /api/health

**Description** : Health check du serveur

**RequÃªte** :
```bash
curl https://userneed-classification-app.onrender.com/api/health
```

**RÃ©ponse** :
```json
{
  "status": "ok",
  "timestamp": 1771241188490,
  "provider": "openrouter",
  "default_model": "anthropic/claude-3.5-haiku"
}
```

#### POST /api/analyze

**Description** : Analyse d'un article via LLM

**RequÃªte** :
```bash
curl -X POST https://userneed-classification-app.onrender.com/api/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "apiKey": "sk-or-v1-...",
    "model": "anthropic/claude-3.5-haiku",
    "prompt": "Article: Titre de l'article\n\nContenu..."
  }'
```

**RÃ©ponse** :
```json
{
  "provider": "openrouter",
  "content": "USERNEED PRINCIPAL : UPDATE ME (SCORE : 60)\nJUSTIFICATION : ActualitÃ© rÃ©cente...",
  "model": "anthropic/claude-3.5-haiku",
  "usage": {
    "prompt_tokens": 245,
    "completion_tokens": 89,
    "total_tokens": 334
  }
}
```

**Codes d'erreur** :
- `401` : ClÃ© API invalide
- `429` : Rate limit dÃ©passÃ©
- `500` : Erreur serveur
- `504` : Timeout (>120s)

### ğŸ”— IntÃ©gration OpenRouter

#### Configuration

```javascript
const API_URL = 'https://openrouter.ai/api/v1/chat/completions';

const headers = {
  'Content-Type': 'application/json',
  'Authorization': `Bearer ${apiKey}`,
  'HTTP-Referer': 'https://franceinfo.fr',
  'X-Title': 'Franceinfo Userneeds Analysis'
};

const body = {
  model: 'anthropic/claude-3.5-haiku',
  messages: [
    { role: 'system', content: systemPrompt },
    { role: 'user', content: userPrompt }
  ],
  max_tokens: 1024
};
```

#### Rate limits

- **OpenRouter** : DÃ©pend du modÃ¨le et du plan
- **Application** : Batch de 2 articles en parallÃ¨le
- **Timeout** : 120 secondes par requÃªte

#### Monitoring des coÃ»ts

OpenRouter Dashboard : https://openrouter.ai/activity

---

## DÃ©veloppement

### ğŸ› ï¸ Configuration dÃ©veloppement

#### Variables d'environnement locales

CrÃ©er `.env` (optionnel) :
```bash
PORT=8000
OPENROUTER_API_KEY=sk-or-v1-...
DEBUG=true
```

#### Mode debug

Ouvrir la console navigateur (F12) pour voir :
- âœ… Logs dÃ©taillÃ©s des requÃªtes
- âœ… Parsing des rÃ©ponses LLM
- âœ… Erreurs et warnings
- âœ… Performance metrics

#### Recharger le serveur

```bash
# ArrÃªter (Ctrl+C)
# RedÃ©marrer
python3 server.py
```

### ğŸ“ Structure du code

#### script.js (Frontend)

**Principales fonctions** :

```javascript
// Parsing Excel
async function parseExcelFile(file)

// Analyse IA
async function analyzeArticle(article, apiKey, model)

// Parsing rÃ©ponse LLM
function parseAIResponse(aiResponse)

// Matrice de confusion
function displayConfusionMatrix(results)

// Export Excel
function exportToExcel()

// Gestion prompts
class PromptManager {
  loadPrompts()
  savePrompts()
  resetPrompts()
}
```

**RÃ¨gles mÃ©tier critiques** :

1. **Normalisation userneeds** (ligne 450) :
```javascript
const userneedVariations = {
  'UPDATE ME': ['UPDATE ME', 'UPDATE', 'UPDATES'],
  'EXPLAIN ME': ['EXPLAIN ME', 'EXPLAIN', 'EXPLANATION'],
  // ...
};
```

2. **Validation scores** (ligne 520) :
```javascript
// Total des 3 scores doit Ãªtre 100
const totalScore = principal.score + secondaire.score + tertiaire.score;
if (totalScore !== 100) {
  console.warn('Scores invalides:', totalScore);
}
```

3. **Parsing multi-formats** (ligne 680) :
```javascript
// Support de 3 formats de rÃ©ponse LLM
// Format 1: "USERNEED PRINCIPAL : UPDATE ME (SCORE : 60)"
// Format 2: "Principal: UPDATE ME - Score: 60"
// Format 3: JSON {"principal": "UPDATE ME", "score": 60}
```

#### server.py (Backend)

**Classe principale** :

```python
class ProxyHTTPRequestHandler(http.server.SimpleHTTPRequestHandler):
    def end_headers(self):
        # CORS headers
        self.send_header('Access-Control-Allow-Origin', '*')

    def do_GET(self):
        # Health check
        if self.path == '/api/health':
            # ...

    def do_POST(self):
        # Proxy vers OpenRouter
        if self.path == '/api/analyze':
            # ...

    def _call_openrouter(self, api_key, model, prompt):
        # Appel API OpenRouter
        # ...
```

**Gestion des erreurs** :

```python
try:
    response = self._call_openrouter(api_key, model, prompt)
except urllib.error.HTTPError as e:
    # Erreur API (401, 429, etc.)
    error_body = e.read()
    self.send_response(e.code)
    self.wfile.write(error_body)
except Exception as e:
    # Erreur serveur
    self.send_response(500)
    error_msg = json.dumps({'error': str(e)})
    self.wfile.write(error_msg.encode('utf-8'))
```

### ğŸ§ª Tests

#### Tests manuels

1. **Health check** :
```bash
curl http://localhost:8000/api/health
```

2. **Analyse test** :
```bash
curl -X POST http://localhost:8000/api/analyze \
  -H "Content-Type: application/json" \
  -d @test_request.json
```

3. **Frontend** :
- Charger `test_petit.xlsx` (10 articles)
- VÃ©rifier parsing et affichage
- Lancer analyse avec modÃ¨le gratuit
- VÃ©rifier matrice et export

#### Tests de charge

```bash
# Analyser 100 articles
# VÃ©rifier :
# - Temps total < 10 minutes
# - Aucune erreur timeout
# - Matrice cohÃ©rente
```

### ğŸ› Debugging

#### ProblÃ¨mes frÃ©quents

**1. "Failed to fetch"**
```
Cause: Serveur non dÃ©marrÃ©
Solution: python3 server.py
```

**2. "Status 401"**
```
Cause: ClÃ© API invalide
Solution: VÃ©rifier config.json ou localStorage
```

**3. "Status 429"**
```
Cause: Rate limit OpenRouter
Solution: Attendre ou rÃ©duire batch size
```

**4. "Timeout"**
```
Cause: RequÃªte > 120s
Solution: Utiliser modÃ¨le plus rapide ou rÃ©duire contenu
```

**5. Parsing Ã©choue**
```
Cause: RÃ©ponse LLM non conforme
Solution: VÃ©rifier/ajuster prompts
```

#### Logs utiles

**Console navigateur** :
```javascript
console.log('ğŸ“Š Analyse dÃ©marrÃ©e:', { model, articlesCount });
console.log('âœ… RÃ©ponse LLM:', aiResponse);
console.log('ğŸ“ˆ RÃ©sultats parsÃ©s:', predictions);
```

**Logs serveur** :
```python
print(f"âœ… Serveur dÃ©marrÃ© sur http://localhost:{PORT}")
print(f"ğŸ” RequÃªte reÃ§ue: {self.path}")
print(f"ğŸ“¡ Appel OpenRouter: {model}")
```

---

## Maintenance et troubleshooting

### ğŸ”„ Mises Ã  jour de dÃ©pendances

#### Python
```bash
pip list --outdated
pip install --upgrade anthropic
pip freeze > requirements.txt
```

#### Frontend (aucune dÃ©pendance)
L'application utilise du JavaScript vanilla sans framework.

### ğŸ“Š Monitoring

#### Render.com Dashboard

AccÃ©der Ã  :
- **Logs** : Logs en temps rÃ©el du serveur
- **Metrics** : CPU, RAM, requÃªtes
- **Events** : Historique des dÃ©ploiements

#### Health check automatique

L'application fait un health check au dÃ©marrage :
```javascript
async function checkServerHealth() {
  const response = await fetch('/api/health');
  if (response.ok) {
    console.log('âœ… Serveur proxy dÃ©tectÃ© et fonctionnel');
  }
}
```

### ğŸ” Diagnostics

#### VÃ©rifier la santÃ© du service

```bash
# Health check
curl https://userneed-classification-app.onrender.com/api/health

# Test analyse
curl -X POST https://userneed-classification-app.onrender.com/api/analyze \
  -H "Content-Type: application/json" \
  -d '{"apiKey":"test","model":"test","prompt":"test"}'
```

#### VÃ©rifier les coÃ»ts OpenRouter

https://openrouter.ai/activity

#### Logs de production

Render Dashboard â†’ Logs :
```
âœ… Serveur dÃ©marrÃ© sur http://localhost:10000
ğŸ“¡ API Analyze activÃ©e (OpenRouter uniquement)
```

### âš ï¸ ProblÃ¨mes de production

#### Service down

**SymptÃ´mes** : Application inaccessible

**Solutions** :
1. VÃ©rifier Render Status : https://status.render.com
2. RedÃ©ployer manuellement sur Render
3. VÃ©rifier les logs pour erreurs

#### Performances dÃ©gradÃ©es

**SymptÃ´mes** : Analyses trÃ¨s lentes

**Solutions** :
1. VÃ©rifier charge serveur (Metrics Render)
2. Utiliser modÃ¨le plus rapide
3. RÃ©duire batch size
4. Upgrader plan Render (si gratuit saturÃ©)

#### Erreurs API frÃ©quentes

**SymptÃ´mes** : Beaucoup d'erreurs 429 ou 500

**Solutions** :
1. VÃ©rifier quotas OpenRouter
2. ImplÃ©menter retry logic
3. RÃ©duire concurrence

---

## Roadmap et Ã©volutions

### ğŸš§ Version actuelle : 1.2

**FonctionnalitÃ©s** :
- âœ… Analyse batch Excel
- âœ… Multi-LLM via OpenRouter (13+ modÃ¨les)
- âœ… Classification 3 niveaux avec scores
- âœ… Matrice de confusion interactive
- âœ… Export Excel
- âœ… Prompts personnalisables
- âœ… ThÃ¨mes clair/sombre
- âœ… DÃ©ploiement production (Render.com)

### ğŸ¯ Version 2.0 (Q2 2026)

**Module Constitution de corpus** :
- ğŸ“ Fetch articles depuis API France Info
- ğŸ“ Qualification manuelle des userneeds
- ğŸ“ Gestion corpus persistant (BDD)
- ğŸ“ CRUD articles avec recherche/filtres

**Module Historisation** :
- ğŸ“ Sauvegarde rÃ©sultats analyses en BDD
- ğŸ“ Historique tests avec mÃ©tadonnÃ©es
- ğŸ“ Consultation rÃ©sultats passÃ©s

**Module Comparaison** :
- ğŸ“ SÃ©lection multi-tests
- ğŸ“ Comparaison cÃ´te-Ã -cÃ´te
- ğŸ“ Analyse prÃ©dictions divergentes
- ğŸ“ Visualisations avancÃ©es (heatmaps, graphiques)

### ğŸ”® Futures Ã©volutions

**Court terme (3-6 mois)** :
- ğŸ”„ API REST publique
- ğŸ”„ Webhooks pour intÃ©gration CMS
- ğŸ”„ Mode hors-ligne avec cache
- ğŸ”„ Tests A/B de prompts

**Moyen terme (6-12 mois)** :
- ğŸ”„ Authentification SSO France TV
- ğŸ”„ Multi-tenant pour autres mÃ©dias
- ğŸ”„ Fine-tuning modÃ¨les personnalisÃ©s
- ğŸ”„ Dashboard analytics avancÃ©

**Long terme (12+ mois)** :
- ğŸ”„ Analyse temps rÃ©el (streaming)
- ğŸ”„ Recommandations automatiques
- ğŸ”„ IntÃ©gration native dans CMS Franceinfo
- ğŸ”„ API mobile

---

## ğŸ“ Support et ressources

### ğŸ”— Liens utiles

- **Application production** : https://userneed-classification-app.onrender.com
- **Repository GitHub** : https://github.com/livz75/userneed-classification-app
- **OpenRouter** : https://openrouter.ai
- **Render Dashboard** : https://dashboard.render.com

### ğŸ“š Documentation externe

- [OpenRouter API Docs](https://openrouter.ai/docs)
- [Render.com Docs](https://render.com/docs)
- [Anthropic Claude API](https://docs.anthropic.com)

### ğŸ¤ Contribution

Pour contribuer au projet :
1. Fork le repository
2. CrÃ©er une branche feature : `git checkout -b feature/nouvelle-fonctionnalite`
3. Commiter les changements : `git commit -m "Add: nouvelle fonctionnalitÃ©"`
4. Pousser : `git push origin feature/nouvelle-fonctionnalite`
5. CrÃ©er une Pull Request

### ğŸ“ Changelog

#### v1.2.0 (16/02/2026)
- âœ¨ Ajout support multi-LLM via OpenRouter (13+ modÃ¨les)
- âœ¨ Configuration via config.json
- âœ¨ Documentation CONFIG.md
- ğŸš€ DÃ©ploiement production sur Render.com
- ğŸ› Fix parsing rÃ©ponses LLM multi-formats

#### v1.1.0 (05/02/2026)
- ğŸš€ Health check automatique
- ğŸ¯ Messages d'erreur dÃ©taillÃ©s
- â±ï¸ Timeout 30 secondes
- ğŸ”§ ModÃ¨le API mis Ã  jour (Sonnet 3.5)
- ğŸ“œ Script dÃ©marrage automatique

#### v1.0.0 (05/02/2026)
- ğŸ¨ ThÃ¨me clair/sombre
- ğŸ¢ Logo Franceinfo
- ğŸ“Š Matrice confusion interactive
- ğŸ“¤ Export Excel multi-feuilles
- ğŸ¯ Prompts personnalisables

---

## ğŸ“„ Licence

Â© 2026 France TÃ©lÃ©visions - Usage interne uniquement

Cette application est dÃ©veloppÃ©e pour un usage interne Ã  France TÃ©lÃ©visions. Toute reproduction, distribution ou utilisation commerciale est interdite sans autorisation prÃ©alable.

---

**Documentation gÃ©nÃ©rÃ©e le 16 fÃ©vrier 2026**

**Version** : 1.2.0

**Auteur** : Livio Ricci (avec assistance Claude Sonnet 4.5)

**Contact** : [Ã€ complÃ©ter]
